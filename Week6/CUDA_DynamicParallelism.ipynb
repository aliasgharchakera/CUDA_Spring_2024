{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmmovania/CUDA_Spring_2024/blob/main/Week6/CUDA_DynamicParallelism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB2MY3st-VUm",
        "outputId": "3c168a4d-528d-47df-c856-8e67cdeae379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-vhbtxkxv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-vhbtxkxv\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 781ff5b76ba6c4c2d80dcbbec9983e147613cc71\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.1.0-py3-none-any.whl size=8011 sha256=e2b2acbb79d726227ace2ffdeb18b901e4debb9cf9419b13a35a389a655ee4ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6a7q6x9f/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.1.0\n",
            "Source files will be saved in \"/tmp/tmpt5645en8\".\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYZ627HO-XKd",
        "outputId": "4d7c309e-94a0-4757-f0ae-439588b896ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dp.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile dp.cu\n",
        "//example given here: https://stackoverflow.com/questions/64516177/call-kernel-inside-cuda-kernel\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "const int N = 100;//33 * 1024;\n",
        "const int threadsPerBlock = 32;// 256;\n",
        "\n",
        "#define imin(a,b) (a<b?a:b)\n",
        "\n",
        "const int blocksPerGrid =  imin( 32, (N+threadsPerBlock-1) / threadsPerBlock );\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "\tif (err != cudaSuccess) {\n",
        "\t\tfprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "\t}\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "__global__ void kernel( float *a, float *b, int N )\n",
        "{\n",
        "\tint i = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\tif(i < N)\n",
        "\t{\n",
        "\t\t\tfor(int j=i; j< min(i+5, N); j++)\n",
        "\t\t\t{\n",
        "\t\t\t\t\tb[i] += a[j];\n",
        "\t\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void kernel_child(int start, int end, float *a, float *b)\n",
        "{\n",
        "\tint j = start + threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\tif(j < end)\n",
        "\t{\n",
        "\t\t\tb[j] += a[j];\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void kernel_parent( float *a, float *b, int start, int end )\n",
        "{\n",
        "\tint i = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "\tb[i] = a[i];\n",
        "\tkernel_child<<< (end-start)/32, 32>>>(start, end, a, b);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tfloat   *a = 0;\n",
        "  float   *b = 0;\n",
        "\tfloat   *c = 0;\n",
        "\n",
        "\t// Allocate Unified Memory -- accessible from CPU or GPU\n",
        "\tcheckCudaErr(cudaMallocManaged(&a, N*sizeof(float)), \"cudaMallocManaged1\");\n",
        "\tcheckCudaErr(cudaMallocManaged(&b, N*sizeof(float)), \"cudaMallocManaged2\");\n",
        "\tcheckCudaErr(cudaMallocManaged(&c, N*sizeof(float)), \"cudaMallocManaged3\");\n",
        "\n",
        "\t// fill in the memory with data\n",
        "\tfor (int i=0; i<N; i++) {\n",
        "\t\ta[i] = i+1;\n",
        "\t\tb[i] = 0;\n",
        "\t\tc[i] = 0;\n",
        "\t}\n",
        "\n",
        "\tkernel<<<blocksPerGrid,threadsPerBlock>>>( a, b, N );\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\n",
        "\tkernel_parent<<<blocksPerGrid,threadsPerBlock>>>( a, b, 0, N-1 );\n",
        "\n",
        "\tfor(int i=0; i<N;++i)\n",
        "\t\tprintf(\"%f\\n\", b[i]);\n",
        "\n",
        "\t// free memory on the gpu side\n",
        "\tcheckCudaErr( cudaFree( a ) , \"cudaFree1\");\n",
        "\tcheckCudaErr( cudaFree( b ) , \"cudaFree2\");\n",
        "\tcheckCudaErr( cudaFree( c ) , \"cudaFree3\");\n",
        "\tcheckCudaErr( cudaDeviceReset(), \"cudaDeviceReset\");\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XZSg1f2nEmM-",
        "outputId": "7f6f91d9-c3c3-4988-9b55-ef8dafe32f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000\n",
            "2.000000\n",
            "3.000000\n",
            "4.000000\n",
            "5.000000\n",
            "6.000000\n",
            "7.000000\n",
            "8.000000\n",
            "9.000000\n",
            "10.000000\n",
            "11.000000\n",
            "12.000000\n",
            "13.000000\n",
            "14.000000\n",
            "15.000000\n",
            "16.000000\n",
            "17.000000\n",
            "18.000000\n",
            "19.000000\n",
            "20.000000\n",
            "21.000000\n",
            "22.000000\n",
            "23.000000\n",
            "24.000000\n",
            "25.000000\n",
            "26.000000\n",
            "27.000000\n",
            "28.000000\n",
            "29.000000\n",
            "30.000000\n",
            "31.000000\n",
            "32.000000\n",
            "33.000000\n",
            "34.000000\n",
            "35.000000\n",
            "36.000000\n",
            "37.000000\n",
            "38.000000\n",
            "39.000000\n",
            "40.000000\n",
            "41.000000\n",
            "42.000000\n",
            "43.000000\n",
            "44.000000\n",
            "45.000000\n",
            "46.000000\n",
            "47.000000\n",
            "48.000000\n",
            "49.000000\n",
            "50.000000\n",
            "51.000000\n",
            "52.000000\n",
            "53.000000\n",
            "54.000000\n",
            "55.000000\n",
            "56.000000\n",
            "57.000000\n",
            "58.000000\n",
            "59.000000\n",
            "60.000000\n",
            "61.000000\n",
            "62.000000\n",
            "126.000000\n",
            "128.000000\n",
            "130.000000\n",
            "132.000000\n",
            "134.000000\n",
            "136.000000\n",
            "138.000000\n",
            "140.000000\n",
            "142.000000\n",
            "144.000000\n",
            "146.000000\n",
            "148.000000\n",
            "150.000000\n",
            "152.000000\n",
            "154.000000\n",
            "156.000000\n",
            "158.000000\n",
            "240.000000\n",
            "243.000000\n",
            "246.000000\n",
            "249.000000\n",
            "252.000000\n",
            "255.000000\n",
            "258.000000\n",
            "261.000000\n",
            "264.000000\n",
            "267.000000\n",
            "270.000000\n",
            "273.000000\n",
            "276.000000\n",
            "279.000000\n",
            "282.000000\n",
            "285.000000\n",
            "288.000000\n",
            "97.000000\n",
            "98.000000\n",
            "99.000000\n",
            "100.000000\n"
          ]
        }
      ],
      "source": [
        "!nvcc -rdc=true dp.cu -o dp\n",
        "!./dp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CUDA_DynamicParallelism.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}